{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce9235cf",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ade515a",
   "metadata": {},
   "source": [
    "In this programming exercise, you will implement the gradient descent algorithm using only numpy. DO NOT use libraries like scikit-learn or scipy.\n",
    "\n",
    "Use the template provided in this notebook to implement gradient descent.\n",
    "\n",
    "Use gradient descent to optimize for the parameters of linear regression, and compare the results to the least-squares solution from last week.\n",
    "\n",
    "When done, paste the code into the moodle-quiz and answer the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bdb0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages\n",
    "import numpy as np\n",
    "from numpy.typing import ArrayLike\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c68ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data\n",
    "\n",
    "\n",
    "def load_data(name: str) -> tuple[ArrayLike, ArrayLike]:\n",
    "    \"\"\"Loads data from provided .npy files and returns the x and y values.\n",
    "\n",
    "    Args:\n",
    "        name (str): The file name of the .npy file to load.\n",
    "\n",
    "    Returns:\n",
    "        tuple[ArrayLike, ArrayLike]: The x and y values of the data. x and y have shape (n,).\n",
    "    \"\"\"\n",
    "    data = np.load(name)\n",
    "    x, y = data.T\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd67dcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the data and the regression model.\n",
    "\n",
    "\n",
    "def plot(x: ArrayLike, y: ArrayLike, w: ArrayLike = None):\n",
    "    \"\"\"Plot the data and linear regression model.\n",
    "\n",
    "    Only for plotting 2D data.\n",
    "\n",
    "    Args:\n",
    "        x (ArrayLike): The input data of shape (n,).\n",
    "        y (ArrayLike): The output data of shape (n,).\n",
    "        w (ArrayLike, optional): The weight and bias of a linear regression. Defaults to None.\n",
    "    \"\"\"\n",
    "\n",
    "    # Plot the data\n",
    "    plt.plot(x, y, \".r\", markersize=8, label=\"Samples\")\n",
    "\n",
    "    # also plot the prediction\n",
    "    if w is not None:\n",
    "        deg = w.shape[0]\n",
    "        x_plot = np.linspace(np.min(x), np.max(x), 100)\n",
    "        X_plot = np.vander(x_plot, deg)\n",
    "\n",
    "        # set plotting range properly\n",
    "        plt.ylim((np.min(y) * 1.2, np.max(y) * 1.2))\n",
    "\n",
    "        plt.plot(\n",
    "            x_plot, X_plot @ w, linewidth=5, color=\"tab:blue\", label=\"Model\"\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8420ce70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtracking_line_search(fg: Callable[[ArrayLike], tuple[float, ArrayLike]], x_0: ArrayLike, d: ArrayLike, alpha:float=0.2, beta:float=0.8) -> ArrayLike:\n",
    "    \"\"\"Performs backtracking line search to find a suitable step size.\n",
    "\n",
    "    Args:\n",
    "        fg (Callable[[ArrayLike], tuple[float, ArrayLike]]): A function returning the function value and its gradient at a given point.\n",
    "        x_0 (ArrayLike): The initial point.\n",
    "        d (ArrayLike): The direction of the line search.\n",
    "        alpha (float, optional): The condition parameter. Should be in (0, 0.5). Defaults to 0.2.\n",
    "        beta (float, optional): The step parameter. Should be in (0, 1). Defaults to 0.8.\n",
    "\n",
    "    Returns:\n",
    "        ArrayLike: The new point after taking the step in the direction d.\n",
    "    \"\"\"\n",
    "    # TODO: Implement backtracking line search\n",
    "    \n",
    "    return x_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7422ee05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(fg: Callable[[ArrayLike], tuple[float, ArrayLike]], x: ArrayLike, niter:int=100) -> ArrayLike:\n",
    "    \"\"\"Gradient descent algorithm.\n",
    "\n",
    "    Args:\n",
    "        fg (Callable[[ArrayLike], tuple[float, ArrayLike]]): The objective function.\n",
    "        x (ArrayLike): The initial point.\n",
    "        niter (int, optional): Number of iteration to perform. Defaults to 100.\n",
    "\n",
    "    Returns:\n",
    "        ArrayLike: The final point after performing gradient descent.\n",
    "    \"\"\"\n",
    "    for _ in range(niter):\n",
    "        # TODO: Implement gradient descent\n",
    "        pass\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f108cc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression(x: ArrayLike, y: ArrayLike) -> ArrayLike:\n",
    "    \"\"\"Finds the linear regression coefficients using gradient descent.\n",
    "\n",
    "    Args:\n",
    "        x (ArrayLike): The input data of shape (n,).\n",
    "        y (ArrayLike): The output data of shape (n,).\n",
    "\n",
    "    Returns:\n",
    "        ArrayLike: The linear regression coefficients.\n",
    "    \"\"\"\n",
    "    # TODO: Compute the objective function and its gradient\n",
    "    X = None\n",
    "    def fg(w: ArrayLike) -> tuple[float, ArrayLike]:\n",
    "        \"\"\"The objective function of the regression problem.\n",
    "\n",
    "        Args:\n",
    "            w (ArrayLike): The weight vector.\n",
    "\n",
    "        Returns:\n",
    "            tuple[float, ArrayLike]: The objective function value and its gradient.\n",
    "        \"\"\"\n",
    "        f = None\n",
    "        g = None\n",
    "        return f, g\n",
    "\n",
    "    w_0 = np.zeros(X.shape[1])\n",
    "    w = gradient_descent(fg, w_0)\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d957482",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"dataset0.npy\", \"dataset1.npy\", \"dataset2.npy\", \"dataset3.npy\"]\n",
    "\n",
    "for dataset in datasets:\n",
    "    x, y = load_data(dataset)\n",
    "    w = regression(x, y)\n",
    "    plot(x, y, w)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
